{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65fdd27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lief\n",
      "  Downloading lief-0.13.2-cp310-cp310-manylinux_2_24_x86_64.whl.metadata (4.0 kB)\n",
      "Downloading lief-0.13.2-cp310-cp310-manylinux_2_24_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lief\n",
      "Successfully installed lief-0.13.2\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.34.55)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.55 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.34.55)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.55->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.55->boto3) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.55->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lief\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d88c0c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MalConv(\n",
      "  (embed): Embedding(257, 8, padding_idx=0)\n",
      "  (conv1): Conv1d(8, 1024, kernel_size=(8,), stride=(8,))\n",
      "  (conv2): Conv1d(1024, 512, kernel_size=(8,), stride=(8,))\n",
      "  (conv3): Conv1d(512, 256, kernel_size=(8,), stride=(8,))\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, embedding_dim=8, window_size=128, output_dim=1):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, embedding_dim, padding_idx=0)  # 256 unique bytes, embedding dimension\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=1024, kernel_size=8, stride=8)\n",
    "        self.conv2 = nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=8, stride=8)\n",
    "        self.conv3 = nn.Conv1d(in_channels=512, out_channels=256, kernel_size=8, stride=8)\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x.clamp(min=0, max=256))  # Ensure indices are within the valid range\n",
    "        x = x.transpose(1, 2)  # Conv1d expects (batch_size, channels, length)\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout after the first convolutional layer\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout after the second convolutional layer\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout after the third convolutional layer\n",
    "        x = torch.squeeze(torch.max(x, dim=2)[0])  # Global max pooling\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)  # Apply dropout after the first fully connected layer\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)  # Apply dropout after the second fully connected layer\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = MalConv()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b9badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load the trained model\n",
    "def load_model(model_path):\n",
    "    model = MalConv()  # Initialize model\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e94616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lief\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def testPE(pe_path):\n",
    "    # Load Model\n",
    "    model = load_model('vMalConv/my_model.pth')\n",
    "\n",
    "    # Load the PE file\n",
    "    try:\n",
    "        pe = lief.parse(pe_path)\n",
    "    except lief.read_error:\n",
    "        return \"Invalid PE file\"\n",
    "\n",
    "    # Extract Features\n",
    "    bytez = np.fromfile(pe_path, dtype=np.uint8)\n",
    "    if len(bytez) < 2000000:\n",
    "        bytez = np.pad(bytez, (0, 2000000 - len(bytez)), mode='constant')\n",
    "    features = torch.tensor(bytez[:2000000], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    # Run the model on the features\n",
    "    with torch.no_grad():\n",
    "        output = model(features)\n",
    "\n",
    "    # Return the prediction\n",
    "    return \"Malware\" if output.item() > 0.5 else \"Benign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6049302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Benign\n"
     ]
    }
   ],
   "source": [
    "# Classify the PE file\n",
    "prediction = testPE('PUTTY.EXE')\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac5468b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"vMalConv/\", arcname=\"model\")\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13fd47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "s3.Bucket(\"jafar.vohra.malconv.model\").upload_file('model.tar.gz', Key='model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9db6687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "------!"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Create a SageMaker model\n",
    "model = PyTorchModel(model_data='s3://jafar.vohra.malconv.model/model.tar.gz',\n",
    "                      role=role,\n",
    "                      entry_point='inference.py',\n",
    "                      #source_dir='model/code/',\n",
    "                      py_version='py3')\n",
    "\n",
    "# Deploy the model to an endpoint\n",
    "predictor = model.deploy(instance_type='ml.m5.xlarge',\n",
    "                         initial_instance_count=1,\n",
    "                         wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
